## Assignment 7: Probability & Statistics I

**Problem 1: Conditional Probability**

There are two boxes. Box A contains 4 red balls and 1 blue ball. Box B contains 2 red balls and 3 blue balls. You choose one of the boxes at random (with equal probability) and then draw one ball at random from the chosen box.

a) What is the probability that the drawn ball is red?
b) Given that the drawn ball is red, what is the probability that it came from Box A?

<br>

**Problem 2: Bayesian Inference in Medical Diagnosis**

A specific disease has a prevalence of 0.2% in a population, meaning 1 in 500 people has the disease. A medical test is developed to detect this disease. The test has the following properties:
- If a person has the disease, the test will be positive with 99% probability (sensitivity).
- If a person does not have the disease, the test will be positive with 5% probability (false positive rate).

A person is selected at random from the population and tests positive. What is the probability that this person actually has the disease?

<br>

**Problem 3: Naive Bayes Classifier for Text Classification**

You are tasked with building a simple spam filter using a Naive Bayes classifier. You are given the following small training dataset of four documents:

| Doc ID | Words in Document | Class      |
|--------|-------------------|------------|
| 1      | 'win', 'money'    | Spam       |
| 2      | 'team', 'meeting' | Not Spam   |
| 3      | 'money', 'prize'  | Spam       |
| 4      | 'team', 'schedule'| Not Spam   |

Your task is to classify the new document: **"win money"**.

Using the Naive Bayes algorithm with **Laplace (add-1) smoothing**, determine whether this new document is more likely to be 'Spam' or 'Not Spam'. You must show the calculation of priors and all necessary likelihoods.

<br>
<br>

### **Solution Report**

Here are the detailed solutions to the assignment problems. Please review them to understand the application of the theoretical concepts.

<br>

**Solution to Problem 1**

Let's define the events:
- $A$: Box A is chosen.
- $B$: Box B is chosen.
- $R$: A red ball is drawn.

From the problem statement, we have the following probabilities:
- Probability of choosing either box:
  $$
  P(A) = 0.5, \quad P(B) = 0.5
  $$
- Conditional probabilities of drawing a red ball from each box:
  - Box A has 4 red, 1 blue (5 total): $P(R|A) = \frac{4}{5}$
  - Box B has 2 red, 3 blue (5 total): $P(R|B) = \frac{2}{5}$

**a) Probability of drawing a red ball**

We use the Law of Total Probability to find the overall probability of drawing a red ball, $P(R)$. This accounts for drawing from either Box A or Box B.

$$
P(R) = P(R|A)P(A) + P(R|B)P(B)
$$

Substituting the values:

$$
P(R) = \left(\frac{4}{5} \times 0.5\right) + \left(\frac{2}{5} \times 0.5\right) = \left(\frac{4}{10}\right) + \left(\frac{2}{10}\right) = \frac{6}{10} = 0.6
$$

The probability that the drawn ball is red is **0.6**.

**b) Probability the red ball came from Box A**

We need to find the posterior probability $P(A|R)$. We use Bayes' Theorem:

$$
P(A|R) = \frac{P(R|A)P(A)}{P(R)}
$$

We have all the necessary components from the previous part:
- $P(R|A) = \frac{4}{5}$
- $P(A) = 0.5$
- $P(R) = 0.6$

Substituting these values into the formula:

$$
P(A|R) = \frac{\frac{4}{5} \times 0.5}{0.6} = \frac{0.8 \times 0.5}{0.6} = \frac{0.4}{0.6} = \frac{2}{3} \approx 0.667
$$

Given that the drawn ball is red, the probability that it came from Box A is **2/3**.

<br>

**Solution to Problem 2**

Let's define the events:
- $D$: A person has the disease.
- $\neg D$: A person does not have the disease.
- $T+$: The test is positive.

From the problem statement, we extract the following probabilities:
- **Prior Probability:** The prevalence of the disease.

$$
P(D) = 0.002
$$

Therefore, the probability of not having the disease is:

$$
P(\neg D) = 1 - P(D) = 1 - 0.002 = 0.998
$$

- **Likelihoods:** The test's accuracy.
  - Sensitivity (True Positive Rate): $P(T+|D) = 0.99$
  - False Positive Rate: $P(T+|\neg D) = 0.05$

We want to find the posterior probability $P(D|T+)$, which is the probability that a person has the disease given that they tested positive. We apply Bayes' Theorem:

$$
P(D|T+) = \frac{P(T+|D)P(D)}{P(T+)}
$$

First, we must calculate the denominator, $P(T+)$, the total probability of testing positive. We use the Law of Total Probability:

$$
P(T+) = P(T+|D)P(D) + P(T+|\neg D)P(\neg D)
$$

$$
P(T+) = (0.99 \times 0.002) + (0.05 \times 0.998)
$$

$$
P(T+) = 0.00198 + 0.0499 = 0.05188
$$

Now we can calculate the posterior probability:

$$
P(D|T+) = \frac{0.00198}{0.05188} \approx 0.03816
$$

The probability that a person who tests positive actually has the disease is approximately **3.82%**. This result is often counter-intuitive. Despite the test's high sensitivity, the extremely low prevalence of the disease means that the vast majority of positive tests are actually false positives from the large, healthy population.

<br>

**Solution to Problem 3**

We need to classify the document "win money" as either 'Spam' or 'Not Spam'. We will compare the posterior probabilities $P(\text{Spam} | \text{"win money"})$ and $P(\text{Not Spam} | \text{"win money"})$. According to the Naive Bayes rule, we choose the class that maximizes $P(C_k) \prod_{i=1}^{n} P(x_i | C_k)$.

**Step 1: Calculate Prior Probabilities**

There are 4 documents in total.
- Number of Spam documents = 2
- Number of Not Spam documents = 2

$$
P(\text{Spam}) = \frac{2}{4} = 0.5
$$

$$
P(\text{Not Spam}) = \frac{2}{4} = 0.5
$$

**Step 2: Calculate Likelihoods with Laplace (add-1) Smoothing**

The vocabulary consists of all unique words in the training set: {'win', 'money', 'team', 'meeting', 'prize', 'schedule'}.
The size of the vocabulary is $V = 6$.

The formula for likelihood with Laplace smoothing is:

$$
P(w_i|C_k) = \frac{\text{count}(w_i, C_k) + 1}{\text{count}(C_k) + V}
$$

where $\text{count}(C_k)$ is the total number of words in class $C_k$.

- Total words in 'Spam' class: 4 ('win', 'money', 'money', 'prize').
- Total words in 'Not Spam' class: 4 ('team', 'meeting', 'team', 'schedule').

Now, let's calculate the likelihoods for the words in our new document "win money".

**For the 'Spam' class:**
- count('win', Spam) = 1
- count('money', Spam) = 2

$$
P(\text{'win'}|\text{Spam}) = \frac{1 + 1}{4 + 6} = \frac{2}{10} = 0.2
$$

$$
P(\text{'money'}|\text{Spam}) = \frac{2 + 1}{4 + 6} = \frac{3}{10} = 0.3
$$

**For the 'Not Spam' class:**
- count('win', Not Spam) = 0
- count('money', Not Spam) = 0

$$
P(\text{'win'}|\text{Not Spam}) = \frac{0 + 1}{4 + 6} = \frac{1}{10} = 0.1
$$

$$
P(\text{'money'}|\text{Not Spam}) = \frac{0 + 1}{4 + 6} = \frac{1}{10} = 0.1
$$

**Step 3: Calculate Posterior Scores**

Now we calculate the proportional posterior probability for each class.

**Score for 'Spam':**
$$
\text{Score}(\text{Spam}) = P(\text{Spam}) \times P(\text{'win'}|\text{Spam}) \times P(\text{'money'}|\text{Spam})
$$

$$
\text{Score}(\text{Spam}) = 0.5 \times 0.2 \times 0.3 = 0.03
$$

**Score for 'Not Spam':**
$$
\text{Score}(\text{Not Spam}) = P(\text{Not Spam}) \times P(\text{'win'}|\text{Not Spam}) \times P(\text{'money'}|\text{Not Spam})
$$

$$
\text{Score}(\text{Not Spam}) = 0.5 \times 0.1 \times 0.1 = 0.005
$$

**Step 4: Make a Prediction**

We compare the scores:
$$
0.03 (\text{Spam}) > 0.005 (\text{Not Spam})
$$

Since the score for the 'Spam' class is higher, the Naive Bayes classifier predicts that the document **"win money" is Spam**.